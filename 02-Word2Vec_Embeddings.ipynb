{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec - Embeddings.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-mpXuyJT9UO",
        "colab_type": "code",
        "outputId": "1cb6052d-4264-4184-e20c-88e914ead066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qILN_kfqIp0x",
        "colab_type": "text"
      },
      "source": [
        "# Dataset: IMDB Movie reviews sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FgeQzCkIjMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words=30000\n",
        "INDEX_FROM=3  # idx 0 => PAD, idx 1 => START, idx 2 => OOV (out of vocab.)\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=num_words+2,)\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEiPTqOBT_V7",
        "colab_type": "code",
        "outputId": "9fcebd5c-5a21-4e10-aac9-41df26dfc39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_words=len(np.unique(np.hstack(data)))\n",
        "print(\"Categories:\", np.unique(targets))\n",
        "print(\"Number of unique words:\", num_words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories: [0 1]\n",
            "Number of unique words: 30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nef02I90wigz",
        "colab_type": "text"
      },
      "source": [
        "Agregar el siguiente archivo al Google Drive\n",
        "\n",
        "https://drive.google.com/open?id=1K5r423yMxBb1Yz2uDT7lto60lu1jqEjl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9mmn9fpUIY6",
        "colab_type": "code",
        "outputId": "62e817ad-911b-499c-cb20-999e1fa49622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tOvUY-MUJGH",
        "colab_type": "code",
        "outputId": "6cfa6ebf-1b24-4b46-8db8-b9d59723c13c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Review length: 234.75892\n",
            "Standard Deviation: 173.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHY8EhzvUdzt",
        "colab_type": "code",
        "outputId": "37a3cfde-3256-4fc9-d151-9cf2bc813a04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"Label:\", targets[0])\n",
        "print(data[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1\n",
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSnvI2LuM5So",
        "colab_type": "text"
      },
      "source": [
        "# Traemos el vocabulario y armamos indice reverso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lY7mGCLUf0M",
        "colab_type": "code",
        "outputId": "8b72ee89-d766-45b6-f356-0b2d19b5339c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "index = imdb.get_word_index()\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "decoded = \" \".join( [reverse_index.get(i - INDEX_FROM, \"#\") for i in data[1]] )\n",
        "print(decoded)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just # trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for # all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R5A_xU9cGM2",
        "colab_type": "code",
        "outputId": "8aadc2e0-81b4-43b0-c1f8-6ac0f2e87137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/GoogleNews-vectors-negative300.bin\", binary=True)  "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDEVfp7RY489",
        "colab_type": "code",
        "outputId": "b3bdb29a-0851-4ac1-c313-43354b5e7f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "w2v.wv[\"car\"]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.13085938,  0.00842285,  0.03344727, -0.05883789,  0.04003906,\n",
              "       -0.14257812,  0.04931641, -0.16894531,  0.20898438,  0.11962891,\n",
              "        0.18066406, -0.25      , -0.10400391, -0.10742188, -0.01879883,\n",
              "        0.05200195, -0.00216675,  0.06445312,  0.14453125, -0.04541016,\n",
              "        0.16113281, -0.01611328, -0.03088379,  0.08447266,  0.16210938,\n",
              "        0.04467773, -0.15527344,  0.25390625,  0.33984375,  0.00756836,\n",
              "       -0.25585938, -0.01733398, -0.03295898,  0.16308594, -0.12597656,\n",
              "       -0.09912109,  0.16503906,  0.06884766, -0.18945312,  0.02832031,\n",
              "       -0.0534668 , -0.03063965,  0.11083984,  0.24121094, -0.234375  ,\n",
              "        0.12353516, -0.00294495,  0.1484375 ,  0.33203125,  0.05249023,\n",
              "       -0.20019531,  0.37695312,  0.12255859,  0.11425781, -0.17675781,\n",
              "        0.10009766,  0.0030365 ,  0.26757812,  0.20117188,  0.03710938,\n",
              "        0.11083984, -0.09814453, -0.3125    ,  0.03515625,  0.02832031,\n",
              "        0.26171875, -0.08642578, -0.02258301, -0.05834961, -0.00787354,\n",
              "        0.11767578, -0.04296875, -0.17285156,  0.04394531, -0.23046875,\n",
              "        0.1640625 , -0.11474609, -0.06030273,  0.01196289, -0.24707031,\n",
              "        0.32617188, -0.04492188, -0.11425781,  0.22851562, -0.01647949,\n",
              "       -0.15039062, -0.13183594,  0.12597656, -0.17480469,  0.02209473,\n",
              "       -0.1015625 ,  0.00817871,  0.10791016, -0.24609375, -0.109375  ,\n",
              "       -0.09375   , -0.01623535, -0.20214844,  0.23144531, -0.05444336,\n",
              "       -0.05541992, -0.20898438,  0.26757812,  0.27929688,  0.17089844,\n",
              "       -0.17578125, -0.02770996, -0.20410156,  0.02392578,  0.03125   ,\n",
              "       -0.25390625, -0.125     , -0.05493164, -0.17382812,  0.28515625,\n",
              "       -0.23242188,  0.0234375 , -0.20117188, -0.13476562,  0.26367188,\n",
              "        0.00769043,  0.20507812, -0.01708984, -0.12988281,  0.04711914,\n",
              "        0.22070312,  0.02099609, -0.29101562, -0.02893066,  0.17285156,\n",
              "        0.04272461, -0.19824219, -0.04003906, -0.16992188,  0.10058594,\n",
              "       -0.09326172,  0.15820312, -0.16503906, -0.06054688,  0.19433594,\n",
              "       -0.07080078, -0.06884766, -0.09619141, -0.07226562,  0.04882812,\n",
              "        0.07324219,  0.11035156,  0.04858398, -0.17675781, -0.33789062,\n",
              "        0.22558594,  0.16308594,  0.05102539, -0.08251953,  0.07958984,\n",
              "        0.08740234, -0.16894531, -0.02160645, -0.19238281,  0.03857422,\n",
              "       -0.05102539,  0.21972656,  0.08007812, -0.21191406, -0.07519531,\n",
              "       -0.15039062,  0.3046875 , -0.17089844,  0.12353516, -0.234375  ,\n",
              "       -0.10742188, -0.06787109,  0.01904297, -0.14160156, -0.22753906,\n",
              "       -0.16308594,  0.14453125, -0.15136719, -0.296875  ,  0.22363281,\n",
              "       -0.10205078, -0.0456543 , -0.21679688, -0.09033203,  0.09375   ,\n",
              "       -0.15332031, -0.01550293,  0.3046875 , -0.23730469,  0.08935547,\n",
              "        0.03710938,  0.02941895, -0.28515625,  0.15820312, -0.00306702,\n",
              "        0.06054688,  0.00497437, -0.15234375, -0.00836182,  0.02197266,\n",
              "       -0.12109375, -0.13867188, -0.2734375 , -0.06835938,  0.08251953,\n",
              "       -0.26367188, -0.16992188,  0.14746094,  0.08496094,  0.02075195,\n",
              "        0.13671875, -0.04931641, -0.0100708 , -0.00369263, -0.10839844,\n",
              "        0.14746094, -0.15527344,  0.16113281,  0.05615234, -0.05004883,\n",
              "       -0.1640625 , -0.26953125,  0.4140625 ,  0.06079102, -0.046875  ,\n",
              "       -0.02514648,  0.10595703,  0.1328125 , -0.16699219, -0.04907227,\n",
              "        0.04663086,  0.05151367, -0.07958984, -0.16503906, -0.29882812,\n",
              "        0.06054688, -0.15332031, -0.00598145,  0.06640625, -0.04516602,\n",
              "        0.24316406, -0.07080078, -0.36914062, -0.23144531, -0.11914062,\n",
              "       -0.08300781,  0.14746094, -0.05761719,  0.23535156, -0.12304688,\n",
              "        0.14648438,  0.13671875,  0.15429688,  0.02111816, -0.09570312,\n",
              "        0.05859375,  0.03979492, -0.08105469,  0.0559082 , -0.16601562,\n",
              "        0.27148438, -0.20117188, -0.00915527,  0.07324219,  0.10449219,\n",
              "        0.34570312, -0.26367188,  0.02099609, -0.40039062, -0.03417969,\n",
              "       -0.15917969, -0.08789062,  0.08203125,  0.23339844,  0.0213623 ,\n",
              "       -0.11328125,  0.05249023, -0.10449219, -0.02380371, -0.08349609,\n",
              "       -0.04003906,  0.01916504, -0.01226807, -0.18261719, -0.06787109,\n",
              "       -0.08496094, -0.03039551, -0.05395508,  0.04248047,  0.12792969,\n",
              "       -0.27539062,  0.28515625, -0.04736328,  0.06494141, -0.11230469,\n",
              "       -0.02575684, -0.04125977,  0.22851562, -0.14941406, -0.15039062],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyJyLhkhNJNX",
        "colab_type": "text"
      },
      "source": [
        "# Armamos la matriz de embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlY6kxXlUv_b",
        "colab_type": "code",
        "outputId": "eaf5bd50-bc91-428d-ccd3-3da846e8c82b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "embed_dim=300\n",
        "embedding_matrix=np.zeros([num_words+4,embed_dim])\n",
        "for word, idx in index.items():\n",
        "  if idx <= num_words and word in w2v.wv:\n",
        "    embedding_matrix[idx+3,:]=w2v.wv[word]\n",
        "    \n",
        "embedding_matrix.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30004, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PJzpmFbRL7j",
        "colab_type": "text"
      },
      "source": [
        "# Hacemos que todos los reviews tengan el mismo largo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HdJ8KrrZszC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen=1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r9jiL4QarNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pad_sequences(data, maxlen=maxlen, value=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiL4twmwas3F",
        "colab_type": "code",
        "outputId": "52a72c86-1f78-4fcf-c751-519db7f0edd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoPdGTyaaudk",
        "colab_type": "code",
        "outputId": "114a6c73-339f-4c1a-b8d9-c5326dbbc873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HdnsE2awBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri0xt9ueaxlK",
        "colab_type": "code",
        "outputId": "4ddf2d3d-837c-4646-859e-a773c0686d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nd_FmZGRVLJ",
        "colab_type": "text"
      },
      "source": [
        "# Armamos el modelo con una Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjoQz25NazxB",
        "colab_type": "code",
        "outputId": "20f84cbd-efd8-479d-9af9-31c5b3320dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "nb_words=num_words+4\n",
        "num_filters=64\n",
        "model = Sequential()\n",
        "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters*2, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
        "\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 300)         9001200   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1000, 64)          134464    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 500, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 500, 128)          57472     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,197,297\n",
            "Trainable params: 196,097\n",
            "Non-trainable params: 9,001,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnkm8psrbO3A",
        "colab_type": "code",
        "outputId": "62dda47a-6ec0-4579-ddcc-32e55c90e19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "model.fit(data, targets,batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 31s 780us/step - loss: 0.3864 - acc: 0.8203 - val_loss: 0.3114 - val_acc: 0.8612\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 30s 745us/step - loss: 0.2704 - acc: 0.8882 - val_loss: 0.2587 - val_acc: 0.8894\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 30s 747us/step - loss: 0.2243 - acc: 0.9092 - val_loss: 0.2697 - val_acc: 0.8862\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 30s 750us/step - loss: 0.1841 - acc: 0.9271 - val_loss: 0.2486 - val_acc: 0.9040\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 30s 741us/step - loss: 0.1437 - acc: 0.9446 - val_loss: 0.2523 - val_acc: 0.9005\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 30s 743us/step - loss: 0.1144 - acc: 0.9566 - val_loss: 0.2897 - val_acc: 0.8975\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 30s 753us/step - loss: 0.0931 - acc: 0.9648 - val_loss: 0.2994 - val_acc: 0.9003\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 30s 740us/step - loss: 0.0765 - acc: 0.9720 - val_loss: 0.3462 - val_acc: 0.8992\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 30s 741us/step - loss: 0.0666 - acc: 0.9756 - val_loss: 0.4657 - val_acc: 0.8751\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 30s 743us/step - loss: 0.0577 - acc: 0.9784 - val_loss: 0.3680 - val_acc: 0.8965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8e20355c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GUS1aYWReop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}